2024-12-14 17:44:35 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: sggwScraper)
2024-12-14 17:44:35 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 23.10.0, Python 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.0.15 3 Sep 2024), cryptography 43.0.0, Platform Windows-11-10.0.26100-SP0
2024-12-14 17:44:35 [scrapy.addons] INFO: Enabled addons:
[]
2024-12-14 17:44:35 [scrapy.extensions.telnet] INFO: Telnet Password: 926d8a9d73939697
2024-12-14 17:44:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2024-12-14 17:44:35 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 30,
 'AUTOTHROTTLE_START_DELAY': 0.2,
 'AUTOTHROTTLE_TARGET_CONCURRENCY': 4,
 'BOT_NAME': 'sggwScraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'sggwScraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['sggwScraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-12-14 17:44:35 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2024-12-14 17:44:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sggwScraper.middlewares.SggwscraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-14 17:44:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-14 17:44:36 [scrapy.middleware] INFO: Enabled item pipelines:
['sggwScraper.pipelines.SggwscraperPipeline',
 'sggwScraper.pipelines.SaveToDataBase']
2024-12-14 17:44:36 [scrapy.core.engine] INFO: Spider opened
2024-12-14 17:44:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-12-14 17:44:36 [sggw] INFO: Spider opened: sggw
2024-12-14 17:44:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-12-14 17:44:36 [scrapy-playwright] INFO: Starting download handler
2024-12-14 17:44:36 [scrapy-playwright] INFO: Starting download handler
2024-12-14 17:44:36 [scrapy-playwright] INFO: Launching 3 startup context(s)
2024-12-14 17:44:36 [scrapy-playwright] INFO: Launching browser chromium
2024-12-14 17:44:36 [scrapy-playwright] INFO: Launching 3 startup context(s)
2024-12-14 17:44:36 [scrapy-playwright] INFO: Launching browser chromium
2024-12-14 17:44:37 [scrapy-playwright] INFO: Browser chromium launched
2024-12-14 17:44:37 [scrapy-playwright] INFO: Browser chromium launched
2024-12-14 17:44:37 [scrapy-playwright] INFO: Startup context(s) launched
2024-12-14 17:44:37 [scrapy-playwright] INFO: Startup context(s) launched
2024-12-14 17:45:11 [scrapy.core.engine] INFO: Closing spider (finished)
2024-12-14 17:45:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1296,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 654427,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 35.041721,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 12, 14, 16, 45, 11, 612202, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 83634,
 'httpcompression/response_count': 2,
 'item_scraped_count': 39,
 'log_count/INFO': 22,
 'playwright/browser_count': 2,
 'playwright/context_count': 7,
 'playwright/context_count/max_concurrent': 4,
 'playwright/context_count/persistent/False': 7,
 'playwright/context_count/remote/False': 7,
 'playwright/page_count': 2,
 'playwright/page_count/max_concurrent': 2,
 'playwright/request_count': 263,
 'playwright/request_count/aborted': 126,
 'playwright/request_count/method/GET': 236,
 'playwright/request_count/method/POST': 27,
 'playwright/request_count/navigation': 4,
 'playwright/request_count/resource_type/document': 4,
 'playwright/request_count/resource_type/fetch': 4,
 'playwright/request_count/resource_type/image': 48,
 'playwright/request_count/resource_type/script': 106,
 'playwright/request_count/resource_type/stylesheet': 78,
 'playwright/request_count/resource_type/xhr': 23,
 'playwright/response_count': 135,
 'playwright/response_count/method/GET': 110,
 'playwright/response_count/method/POST': 25,
 'playwright/response_count/resource_type/document': 4,
 'playwright/response_count/resource_type/fetch': 2,
 'playwright/response_count/resource_type/script': 106,
 'playwright/response_count/resource_type/xhr': 23,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2024, 12, 14, 16, 44, 36, 570481, tzinfo=datetime.timezone.utc)}
2024-12-14 17:45:11 [scrapy.core.engine] INFO: Spider closed (finished)
2024-12-14 17:45:11 [scrapy-playwright] INFO: Closing download handler
2024-12-14 17:45:11 [scrapy-playwright] INFO: Closing browser
2024-12-14 17:45:12 [scrapy-playwright] INFO: Closing download handler
2024-12-14 17:45:12 [scrapy-playwright] INFO: Closing browser
2024-12-14 17:45:13 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: sggwScraper)
2024-12-14 17:45:13 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 23.10.0, Python 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.0.15 3 Sep 2024), cryptography 43.0.0, Platform Windows-11-10.0.26100-SP0
2024-12-14 17:45:13 [scrapy.addons] INFO: Enabled addons:
[]
2024-12-14 17:45:13 [scrapy.extensions.telnet] INFO: Telnet Password: 22c719753cfc71b3
2024-12-14 17:45:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2024-12-14 17:45:13 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 30,
 'AUTOTHROTTLE_START_DELAY': 0.2,
 'AUTOTHROTTLE_TARGET_CONCURRENCY': 4,
 'BOT_NAME': 'sggwScraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'sggwScraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['sggwScraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-12-14 17:45:13 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2024-12-14 17:45:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sggwScraper.middlewares.SggwscraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-14 17:45:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-14 17:45:14 [scrapy.middleware] INFO: Enabled item pipelines:
['sggwScraper.pipelines.SggwscraperPipeline',
 'sggwScraper.pipelines.SaveToDataBase']
2024-12-14 17:45:14 [scrapy.core.engine] INFO: Spider opened
2024-12-14 17:45:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-12-14 17:45:14 [publications] INFO: Spider opened: publications
2024-12-14 17:45:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-12-14 17:45:14 [scrapy-playwright] INFO: Starting download handler
2024-12-14 17:45:14 [scrapy-playwright] INFO: Starting download handler
2024-12-14 17:45:15 [scrapy-playwright] INFO: Launching 3 startup context(s)
2024-12-14 17:45:15 [scrapy-playwright] INFO: Launching browser chromium
2024-12-14 17:45:15 [scrapy-playwright] INFO: Launching 3 startup context(s)
2024-12-14 17:45:15 [scrapy-playwright] INFO: Launching browser chromium
2024-12-14 17:45:15 [scrapy-playwright] INFO: Browser chromium launched
2024-12-14 17:45:15 [scrapy-playwright] INFO: Browser chromium launched
2024-12-14 17:45:15 [scrapy-playwright] INFO: Startup context(s) launched
2024-12-14 17:45:15 [scrapy-playwright] INFO: Startup context(s) launched
2024-12-14 17:46:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://bw.sggw.edu.pl/info/book/WULS6f1244f02e304ae481b07a42dba7b576?r=publication&ps=20&tab=&title=Publication%2B%25E2%2580%2593%2BDawne%2Bodmiany%2Bdrzew%2Bowocowych%2Buprawianych%2Bw%2BPolsce%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BLife%2BSciences%2B-%2BSGGW&lang=en>
Traceback (most recent call last):
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\twisted\internet\defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\twisted\python\failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\twisted\internet\defer.py", line 1248, in adapt
    extracted: _SelfResultT | Failure = result.result()
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\scrapy_playwright\_utils.py", line 120, in _handle_coro
    future.set_result(await coro)
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\scrapy_playwright\handler.py", line 379, in _download_request
    return await self._download_request_with_retry(request=request, spider=spider)
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\scrapy_playwright\handler.py", line 432, in _download_request_with_retry
    return await self._download_request_with_page(request, page, spider)
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\scrapy_playwright\handler.py", line 480, in _download_request_with_page
    await self._apply_page_methods(page, request, spider)
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\scrapy_playwright\handler.py", line 631, in _apply_page_methods
    pm.result = await _maybe_await(method(*pm.args, **pm.kwargs))
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\scrapy_playwright\_utils.py", line 21, in _maybe_await
    return await obj
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\playwright\async_api\_generated.py", line 8158, in wait_for_selector
    await self._impl_obj.wait_for_selector(
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\playwright\_impl\_page.py", line 426, in wait_for_selector
    return await self._main_frame.wait_for_selector(**locals_to_params(locals()))
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\playwright\_impl\_frame.py", line 323, in wait_for_selector
    await self._channel.send("waitForSelector", locals_to_params(locals()))
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\playwright\_impl\_connection.py", line 59, in send
    return await self._connection.wrap_api_call(
  File "C:\Users\Kamil\anaconda3\envs\Scraping\Lib\site-packages\playwright\_impl\_connection.py", line 520, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
AssertionError: Page.wait_for_selector: Route.continue_: 
2024-12-14 17:46:14 [scrapy.extensions.logstats] INFO: Crawled 118 pages (at 118 pages/min), scraped 94 items (at 94 items/min)
2024-12-14 17:47:14 [scrapy.extensions.logstats] INFO: Crawled 118 pages (at 0 pages/min), scraped 94 items (at 0 items/min)
2024-12-14 17:48:14 [scrapy.extensions.logstats] INFO: Crawled 118 pages (at 0 pages/min), scraped 94 items (at 0 items/min)
